{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask-ngrok in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (0.0.25)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from flask-ngrok) (2.24.0)\n",
      "Requirement already satisfied: Flask>=0.8 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from flask-ngrok) (1.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from requests->flask-ngrok) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from requests->flask-ngrok) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from requests->flask-ngrok) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from requests->flask-ngrok) (3.0.4)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['From', 'To', 'Time', 'TrainName', 'Distance', 'Fare ', 'TrainNumber',\n",
       "       'Location '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "database=pd.read_csv(\"../dataset/database.csv\")\n",
    "database.head()\n",
    "database.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(new_labels,new_tokens):\n",
    "  entities={}\n",
    "  flag = False;\n",
    "  flag1= False;\n",
    "  for key, word in zip(new_labels,new_tokens):\n",
    "    if(key == \"B-geo\" and flag==False):\n",
    "      entities[\"From\"] = word\t\n",
    "      flag = True\n",
    "    if(key==\"B-geo\" and flag):\n",
    "      entities[\"To\"] = word\n",
    "      flag1=True\n",
    "    if(key == \"B-tim\" and  word.isdigit()==False):\n",
    "      entities[\"Time\"] = word\n",
    "    if(len(word)==5 and word.isdigit()):\n",
    "        entities[\"TrainNumber\"]=word\n",
    "    \n",
    "  return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CallIntent(intent_output,entities):\n",
    "  switcher = { \n",
    "        \"TrainAvailable\": TrainAvailable,\n",
    "        \"GetDistance\": GetDistance,\n",
    "        \"TrainRoute\": TrainRoute,\n",
    "        \"TrainFare\": TrainFare,\n",
    "    } \n",
    "  item=switcher.get(intent_output)\n",
    "  if(callable(item)):\n",
    "    return item(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDistance(entities):\n",
    "  outf=[]\n",
    "  for i,row in database.iterrows():\n",
    "    if(entities[\"From\"].lower()==row[\"From\"].lower() and entities[\"To\"].lower()==row[\"To\"].lower()):\n",
    "      outf.append(\"The distance from {} to {} is {}\" .format(entities[\"From\"],entities[\"To\"],row[\"Distance\"]))\n",
    "      return outf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainAvailable(entities):\n",
    "  outf=[]\n",
    "  outf.append((\"Trains Available from {} to {} is\" .format(entities[\"From\"],entities[\"To\"])))\n",
    "  outf.append((\"TrainNo\\tTrainName\\tTime\\tFare\"))\n",
    "  for i,row in database.iterrows():\n",
    "    if(entities[\"From\"].lower()==row[\"From\"].lower() and entities[\"To\"].lower()==row[\"To\"].lower()):\n",
    "      outf.append(((\"{}\\t{}\\t{}\\t{}\" .format(row[\"TrainNumber\"],row[\"TrainName\"],row[\"Time\"],row[\"Fare \"]))))\n",
    "  print(outf)\n",
    "  return outf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainRoute(entities):\n",
    "  outf=[]\n",
    "  if \"TrainNumber\" in entities.keys():\n",
    "    for i,row in database.iterrows():\n",
    "      if(int(entities[\"TrainNumber\"])==row[\"TrainNumber\"]):\n",
    "        outf.append(\"This train runs from {} to {} and current location is {}\" .format(row[\"From\"],row[\"To\"],row[\"Location \"]))\n",
    "    return outf\n",
    "  else:\n",
    "    return [\"please enter train number also\"]\n",
    "  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainFare(entities):\n",
    "  outf=[]\n",
    "  outf.append(\"The fare for the trains: \")\n",
    "  outf.append(\"TrainNo\\tTrainName\\tFare\")\n",
    "  for i,row in database.iterrows():\n",
    "    if(entities[\"From\"].lower()==row[\"From\"].lower() and entities[\"To\"].lower()==row[\"To\"].lower()):\n",
    "      outf.append(((\"{}\\t{}\\t{}\" .format(row[\"TrainNumber\"],row[\"TrainName\"],row[\"Fare \"]))))\n",
    "  return outf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==2.6.0 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from transformers==2.6.0) (0.5.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from transformers==2.6.0) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from transformers==2.6.0) (4.50.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from transformers==2.6.0) (2.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from transformers==2.6.0) (2020.9.27)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\roaming\\python\\python37\\site-packages (from transformers==2.6.0) (1.19.5)\n",
      "Requirement already satisfied: boto3 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from transformers==2.6.0) (1.15.16)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from transformers==2.6.0) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from transformers==2.6.0) (0.1.91)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from requests->transformers==2.6.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from requests->transformers==2.6.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from requests->transformers==2.6.0) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from requests->transformers==2.6.0) (2.10)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from boto3->transformers==2.6.0) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from boto3->transformers==2.6.0) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.19.0,>=1.18.16 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from boto3->transformers==2.6.0) (1.18.16)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from sacremoses->transformers==2.6.0) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from sacremoses->transformers==2.6.0) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from sacremoses->transformers==2.6.0) (0.17.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\asus\\anaconda3\\envs\\env\\lib\\site-packages (from botocore<1.19.0,>=1.18.16->boto3->transformers==2.6.0) (2.8.1)\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [05/Feb/2021 09:05:51] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Running on http://7ae9fe6b0de6.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n",
      "1 2 3 4 \n",
      "Predicting labels for 1 test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-05 09:05:57,743] ERROR in app: Exception on /get [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-10-0a55388ac17d>\", line 139, in get_bot_response\n",
      "    return json.dumps(CallIntent(intent_output,entities))\n",
      "NameError: name 'json' is not defined\n",
      "127.0.0.1 - - [05/Feb/2021 09:05:57] \"\u001b[35m\u001b[1mGET /get?msg=hii HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DONE.\n",
      "TrainRoute\n",
      "1 2 3 4 \n",
      "Predicting labels for 1 test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-05 09:06:08,827] ERROR in app: Exception on /get [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\envs\\env\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-10-0a55388ac17d>\", line 139, in get_bot_response\n",
      "    return json.dumps(CallIntent(intent_output,entities))\n",
      "NameError: name 'json' is not defined\n",
      "127.0.0.1 - - [05/Feb/2021 09:06:08] \"\u001b[35m\u001b[1mGET /get?msg=show%20me%20trains%20from%20delhi%20to%20mumbai HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DONE.\n",
      "TrainAvailable\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "!pip install transformers==2.6.0\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertForTokenClassification\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    " \n",
    " \n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)  \n",
    "\n",
    "# # NER\n",
    "device = torch.device(\"cpu\")\n",
    "data = pd.read_csv(\"../dataset/ner_dataset.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "tag_values = list(set(data[\"Tag\"].values))\n",
    "tag_values.append(\"PAD\")\n",
    "tag_values.sort()\n",
    "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
    " \n",
    "output_dir = '../output/ner/'\n",
    "model = BertForTokenClassification.from_pretrained(output_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# INTENT\n",
    "device = torch.device(\"cpu\")\n",
    "train=pd.read_csv(\"../dataset/train.csv\")\n",
    "labels = train.intent.values\n",
    "input_labels = []\n",
    "k = 1;\n",
    "mp = {}\n",
    "mpp= {}\n",
    "for sent in labels:\n",
    "    mp[sent]=0;\n",
    "for sent in labels:\n",
    "    if(mp[sent] == 0):\n",
    "        mp[sent] = k\n",
    "        mpp[k]=sent\n",
    "        k = k + 1\n",
    "    input_labels.append(mp[sent]-1)\n",
    "\n",
    "output_dir = '../output/intent/'\n",
    "model1 = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "model1.to(device)\n",
    "tokenizer1 = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model1.to(device)\n",
    "\n",
    " \n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/get')\n",
    "def get_bot_response():\n",
    "  print(\"1 2 3 4 \");\n",
    "  userText = request.args.get('msg')\n",
    "  sentences = [userText]\n",
    "  # NER\n",
    "  test_sentence=sentences[0]\n",
    "  model.eval()\n",
    "  input_ids = []\n",
    "  tokenized_sentence = tokenizer.encode(test_sentence)\n",
    "  input_ids = torch.tensor([tokenized_sentence])\n",
    "  with torch.no_grad():\n",
    "    output = model(input_ids)\n",
    "  label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "  tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "  new_tokens, new_labels = [], []\n",
    "  for token, label_idx in zip(tokens, label_indices[0]):\n",
    "      if token.startswith(\"##\"):\n",
    "          new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "      else:\n",
    "          new_labels.append(tag_values[label_idx])\n",
    "          new_tokens.append(token)\n",
    "  # for token, label in zip(new_tokens, new_labels):\n",
    "  #   print(\"{}\\t{}\".format(label, token))\n",
    "\n",
    "  # INTENT\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "\n",
    "  for sent in sentences:\n",
    "      encoded_dict = tokenizer1.encode_plus(\n",
    "                          sent,                      \n",
    "                          add_special_tokens = True, \n",
    "                          max_length = 64,           \n",
    "                          pad_to_max_length = True,\n",
    "                          return_attention_mask = True,    \n",
    "                          return_tensors = 'pt', \n",
    "                          truncation=True,     \n",
    "                    )    \n",
    "      input_ids.append(encoded_dict['input_ids'])\n",
    "      attention_masks.append(encoded_dict['attention_mask'])\n",
    "  input_ids = torch.cat(input_ids, dim=0)\n",
    "  attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "  batch_size = 32  \n",
    "\n",
    "  prediction_data = TensorDataset(input_ids, attention_masks )\n",
    "  prediction_sampler = SequentialSampler(prediction_data)\n",
    "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "  print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "  model1.eval()\n",
    "  predictions , true_labels = [], []\n",
    "  for batch in prediction_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask  = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model1(b_input_ids, token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.append(logits)\n",
    "\n",
    "  print('    DONE.')\n",
    "\n",
    "  flat_predictions = np.concatenate(predictions, axis=0)\n",
    "  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "  intent_output=mpp[flat_predictions[0]+1]\n",
    "  print(intent_output)\n",
    "\n",
    "  # Final Prediction\n",
    "  entities=preprocessing(new_labels,new_tokens)\n",
    "  # for i,j in zip(new_labels,new_tokens):\n",
    "  #   print(i)\n",
    "  #   print(j)\n",
    "    \n",
    "  return json.dumps(CallIntent(intent_output,entities))\n",
    "\n",
    "# @app.route(\"/get\")\n",
    "# def get_bot_response():\n",
    "#     userText = request.args.get('msg')\n",
    "#     return str(bot.CallIntent(userText))\n",
    "\n",
    "\n",
    "app.run()\n",
    "if __name__ == '__main__':\n",
    "  app.run(debug=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
